{"allContent":{"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/docs","tagsPath":"/docs/tags","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs","isLast":true,"routePriority":-1,"sidebarFilePath":"C:\\Users\\Zainabayaz\\OneDrive\\Desktop\\hachathon1\\sidebars.js","contentPath":"C:\\Users\\Zainabayaz\\OneDrive\\Desktop\\hachathon1\\docs","docs":[{"id":"AUTH_SYSTEM_DESIGN","title":"Authentication & Personalization System Design","description":"Technology Stack: Docusaurus (Frontend), Better-Auth (Auth Engine), Neon Serverless Postgres (Database), Node.js/Hono (Backend API).","source":"@site/docs/AUTH_SYSTEM_DESIGN.md","sourceDirName":".","slug":"/AUTH_SYSTEM_DESIGN","permalink":"/docs/AUTH_SYSTEM_DESIGN","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/AUTH_SYSTEM_DESIGN.md","tags":[],"version":"current","frontMatter":{}},{"id":"capstone-project/capstone-intro","title":"Capstone Project: Pick-and-Place with Humanoid","description":"Integrated project combining ROS 2, Isaac Sim, and VLA concepts.","source":"@site/docs/capstone-project/capstone-intro.md","sourceDirName":"capstone-project","slug":"/capstone-project/capstone-intro","permalink":"/docs/capstone-project/capstone-intro","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/capstone-project/capstone-intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"id":"capstone-intro","title":"Capstone Project: Pick-and-Place with Humanoid","description":"Integrated project combining ROS 2, Isaac Sim, and VLA concepts."},"sidebar":"tutorialSidebar","previous":{"title":"Voice-to-Action & Cognitive Planning","permalink":"/docs/module-4-vla/voice-cognitive-planning"}},{"id":"demo-auth","title":"Auth & Personalization Demo","description":"This page demonstrates the adaptive content system. Use the Auth Debug panel (bottom-right) to toggle your login status and change your profile.","source":"@site/docs/demo-auth.mdx","sourceDirName":".","slug":"/demo-auth","permalink":"/docs/demo-auth","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/demo-auth.mdx","tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"sidebar_position":10,"title":"Auth & Personalization Demo"}},{"id":"intro","title":"Physical AI & Humanoid Robotics","description":"Build robots that see, speak, plan, and act. This textbook takes you from ROS 2 fundamentals to AI-native humanoid control with NVIDIA Isaac and Vision-Language-Action (VLA) agents.","source":"@site/docs/intro.md","sourceDirName":".","slug":"/intro","permalink":"/docs/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","next":{"title":"Module 1: ROS 2 – The Robotic Nervous System","permalink":"/docs/module-1-ros2/ros2-intro"}},{"id":"module-1-ros2/rclpy-python-agents","title":"rclpy and Python Agents","description":"Authoring Python nodes, parameters, timers, composition, and agent orchestration.","source":"@site/docs/module-1-ros2/rclpy-python-agents.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/rclpy-python-agents","permalink":"/docs/module-1-ros2/rclpy-python-agents","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-1-ros2/rclpy-python-agents.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"rclpy-python-agents","title":"rclpy and Python Agents","description":"Authoring Python nodes, parameters, timers, composition, and agent orchestration.","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Nodes, Topics, Services, Actions","permalink":"/docs/module-1-ros2/ros2-communication"},"next":{"title":"URDF for Humanoid Robots","permalink":"/docs/module-1-ros2/urdf-humanoids"}},{"id":"module-1-ros2/ros2-architecture","title":"ROS 2 Architecture","description":"Graph, middleware, QoS, executors, and composition for humanoid robotics.","source":"@site/docs/module-1-ros2/ros2-architecture.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/ros2-architecture","permalink":"/docs/module-1-ros2/ros2-architecture","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-1-ros2/ros2-architecture.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"ros2-architecture","title":"ROS 2 Architecture","description":"Graph, middleware, QoS, executors, and composition for humanoid robotics.","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Module 1: ROS 2 – The Robotic Nervous System","permalink":"/docs/module-1-ros2/ros2-intro"},"next":{"title":"Nodes, Topics, Services, Actions","permalink":"/docs/module-1-ros2/ros2-communication"}},{"id":"module-1-ros2/ros2-communication","title":"Nodes, Topics, Services, Actions","description":"Communication patterns for humanoid robotics in ROS 2.","source":"@site/docs/module-1-ros2/ros2-communication.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/ros2-communication","permalink":"/docs/module-1-ros2/ros2-communication","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-1-ros2/ros2-communication.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"ros2-communication","title":"Nodes, Topics, Services, Actions","description":"Communication patterns for humanoid robotics in ROS 2.","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"ROS 2 Architecture","permalink":"/docs/module-1-ros2/ros2-architecture"},"next":{"title":"rclpy and Python Agents","permalink":"/docs/module-1-ros2/rclpy-python-agents"}},{"id":"module-1-ros2/ros2-intro","title":"Module 1: ROS 2 – The Robotic Nervous System","description":"Introduction to ROS 2 architecture, nodes, and communication for humanoid robotics.","source":"@site/docs/module-1-ros2/ros2-intro.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/ros2-intro","permalink":"/docs/module-1-ros2/ros2-intro","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-1-ros2/ros2-intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"id":"ros2-intro","title":"Module 1: ROS 2 – The Robotic Nervous System","description":"Introduction to ROS 2 architecture, nodes, and communication for humanoid robotics."},"sidebar":"tutorialSidebar","previous":{"title":"Physical AI & Humanoid Robotics","permalink":"/docs/intro"},"next":{"title":"ROS 2 Architecture","permalink":"/docs/module-1-ros2/ros2-architecture"}},{"id":"module-1-ros2/urdf-humanoids","title":"URDF for Humanoid Robots","description":"Modeling links, joints, collisions, and semantics for humanoids in ROS 2.","source":"@site/docs/module-1-ros2/urdf-humanoids.md","sourceDirName":"module-1-ros2","slug":"/module-1-ros2/urdf-humanoids","permalink":"/docs/module-1-ros2/urdf-humanoids","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-1-ros2/urdf-humanoids.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"urdf-humanoids","title":"URDF for Humanoid Robots","description":"Modeling links, joints, collisions, and semantics for humanoids in ROS 2.","sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"rclpy and Python Agents","permalink":"/docs/module-1-ros2/rclpy-python-agents"},"next":{"title":"Module 2: Digital Twin – Gazebo & Unity","permalink":"/docs/module-2-digital-twin/digital-twin-intro"}},{"id":"module-2-digital-twin/digital-twin-intro","title":"Module 2: Digital Twin – Gazebo & Unity","description":"Simulating humanoid physics and environments using Gazebo and Unity.","source":"@site/docs/module-2-digital-twin/digital-twin-intro.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/digital-twin-intro","permalink":"/docs/module-2-digital-twin/digital-twin-intro","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-2-digital-twin/digital-twin-intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"id":"digital-twin-intro","title":"Module 2: Digital Twin – Gazebo & Unity","description":"Simulating humanoid physics and environments using Gazebo and Unity."},"sidebar":"tutorialSidebar","previous":{"title":"URDF for Humanoid Robots","permalink":"/docs/module-1-ros2/urdf-humanoids"},"next":{"title":"Physics Simulation Fundamentals","permalink":"/docs/module-2-digital-twin/physics-fundamentals"}},{"id":"module-2-digital-twin/gazebo-setup","title":"Gazebo Environment Setup","description":"Install, launch, spawn entities, and integrate ROS 2.","source":"@site/docs/module-2-digital-twin/gazebo-setup.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/gazebo-setup","permalink":"/docs/module-2-digital-twin/gazebo-setup","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-2-digital-twin/gazebo-setup.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"gazebo-setup","title":"Gazebo Environment Setup","description":"Install, launch, spawn entities, and integrate ROS 2.","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Physics Simulation Fundamentals","permalink":"/docs/module-2-digital-twin/physics-fundamentals"},"next":{"title":"URDF & SDF for Humanoid Robots","permalink":"/docs/module-2-digital-twin/urdf-sdf-humanoids"}},{"id":"module-2-digital-twin/physics-fundamentals","title":"Physics Simulation Fundamentals","description":"Time step, solvers, contact, constraints, and stability for humanoids.","source":"@site/docs/module-2-digital-twin/physics-fundamentals.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/physics-fundamentals","permalink":"/docs/module-2-digital-twin/physics-fundamentals","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-2-digital-twin/physics-fundamentals.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"physics-fundamentals","title":"Physics Simulation Fundamentals","description":"Time step, solvers, contact, constraints, and stability for humanoids.","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Module 2: Digital Twin – Gazebo & Unity","permalink":"/docs/module-2-digital-twin/digital-twin-intro"},"next":{"title":"Gazebo Environment Setup","permalink":"/docs/module-2-digital-twin/gazebo-setup"}},{"id":"module-2-digital-twin/sensor-simulation","title":"Sensor Simulation: LiDAR, Depth Camera, IMU","description":"Configuring simulated sensors and ROS 2 bridges for humanoids.","source":"@site/docs/module-2-digital-twin/sensor-simulation.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/sensor-simulation","permalink":"/docs/module-2-digital-twin/sensor-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-2-digital-twin/sensor-simulation.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"id":"sensor-simulation","title":"Sensor Simulation: LiDAR, Depth Camera, IMU","description":"Configuring simulated sensors and ROS 2 bridges for humanoids.","sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"URDF & SDF for Humanoid Robots","permalink":"/docs/module-2-digital-twin/urdf-sdf-humanoids"},"next":{"title":"Unity for High-Fidelity HRI","permalink":"/docs/module-2-digital-twin/unity-hri"}},{"id":"module-2-digital-twin/unity-hri","title":"Unity for High-Fidelity HRI","description":"Unity Robotics Hub, ROS–TCP Bridge, and interactive HRI scenes.","source":"@site/docs/module-2-digital-twin/unity-hri.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/unity-hri","permalink":"/docs/module-2-digital-twin/unity-hri","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-2-digital-twin/unity-hri.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"id":"unity-hri","title":"Unity for High-Fidelity HRI","description":"Unity Robotics Hub, ROS–TCP Bridge, and interactive HRI scenes.","sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Sensor Simulation: LiDAR, Depth Camera, IMU","permalink":"/docs/module-2-digital-twin/sensor-simulation"},"next":{"title":"Module 3: AI-Robot Brain – NVIDIA Isaac","permalink":"/docs/module-3-ai-robot-brain/isaac-intro"}},{"id":"module-2-digital-twin/urdf-sdf-humanoids","title":"URDF & SDF for Humanoid Robots","description":"Modeling humanoids with URDF/XACRO and SDF worlds for simulation.","source":"@site/docs/module-2-digital-twin/urdf-sdf-humanoids.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/urdf-sdf-humanoids","permalink":"/docs/module-2-digital-twin/urdf-sdf-humanoids","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-2-digital-twin/urdf-sdf-humanoids.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"urdf-sdf-humanoids","title":"URDF & SDF for Humanoid Robots","description":"Modeling humanoids with URDF/XACRO and SDF worlds for simulation.","sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Gazebo Environment Setup","permalink":"/docs/module-2-digital-twin/gazebo-setup"},"next":{"title":"Sensor Simulation: LiDAR, Depth Camera, IMU","permalink":"/docs/module-2-digital-twin/sensor-simulation"}},{"id":"module-3-ai-robot-brain/isaac-ecosystem","title":"Introduction to NVIDIA Isaac Ecosystem","description":"Overview of Isaac Sim, Isaac ROS, Replicator, Lab/Gym, and deployment.","source":"@site/docs/module-3-ai-robot-brain/isaac-ecosystem.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/isaac-ecosystem","permalink":"/docs/module-3-ai-robot-brain/isaac-ecosystem","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3-ai-robot-brain/isaac-ecosystem.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"id":"isaac-ecosystem","title":"Introduction to NVIDIA Isaac Ecosystem","description":"Overview of Isaac Sim, Isaac ROS, Replicator, Lab/Gym, and deployment.","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Module 3: AI-Robot Brain – NVIDIA Isaac","permalink":"/docs/module-3-ai-robot-brain/isaac-intro"},"next":{"title":"Isaac Sim and Photorealistic Simulation","permalink":"/docs/module-3-ai-robot-brain/isaac-sim-photoreal"}},{"id":"module-3-ai-robot-brain/isaac-intro","title":"Module 3: AI-Robot Brain – NVIDIA Isaac","description":"Leveraging NVIDIA Isaac for high-performance AI and robotics simulation.","source":"@site/docs/module-3-ai-robot-brain/isaac-intro.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/isaac-intro","permalink":"/docs/module-3-ai-robot-brain/isaac-intro","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3-ai-robot-brain/isaac-intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"id":"isaac-intro","title":"Module 3: AI-Robot Brain – NVIDIA Isaac","description":"Leveraging NVIDIA Isaac for high-performance AI and robotics simulation."},"sidebar":"tutorialSidebar","previous":{"title":"Unity for High-Fidelity HRI","permalink":"/docs/module-2-digital-twin/unity-hri"},"next":{"title":"Introduction to NVIDIA Isaac Ecosystem","permalink":"/docs/module-3-ai-robot-brain/isaac-ecosystem"}},{"id":"module-3-ai-robot-brain/isaac-sim-photoreal","title":"Isaac Sim and Photorealistic Simulation","description":"USD, ray tracing, sensors, and ROS 2 bridge for humanoids.","source":"@site/docs/module-3-ai-robot-brain/isaac-sim-photoreal.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/isaac-sim-photoreal","permalink":"/docs/module-3-ai-robot-brain/isaac-sim-photoreal","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3-ai-robot-brain/isaac-sim-photoreal.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"isaac-sim-photoreal","title":"Isaac Sim and Photorealistic Simulation","description":"USD, ray tracing, sensors, and ROS 2 bridge for humanoids.","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Introduction to NVIDIA Isaac Ecosystem","permalink":"/docs/module-3-ai-robot-brain/isaac-ecosystem"},"next":{"title":"Synthetic Data Generation for Humanoid Robots","permalink":"/docs/module-3-ai-robot-brain/synthetic-data-humanoids"}},{"id":"module-3-ai-robot-brain/nav2-vslam","title":"Isaac ROS VSLAM & Nav2","description":"Hardware-accelerated Visual SLAM and navigation for bipedal humanoids.","source":"@site/docs/module-3-ai-robot-brain/nav2-vslam.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/nav2-vslam","permalink":"/docs/module-3-ai-robot-brain/nav2-vslam","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3-ai-robot-brain/nav2-vslam.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"id":"nav2-vslam","title":"Isaac ROS VSLAM & Nav2","description":"Hardware-accelerated Visual SLAM and navigation for bipedal humanoids."},"sidebar":"tutorialSidebar","previous":{"title":"Synthetic Data Generation for Humanoid Robots","permalink":"/docs/module-3-ai-robot-brain/synthetic-data-humanoids"},"next":{"title":"Module 4: Vision-Language-Action (VLA)","permalink":"/docs/module-4-vla/vla-intro"}},{"id":"module-3-ai-robot-brain/synthetic-data-humanoids","title":"Synthetic Data Generation for Humanoid Robots","description":"Isaac Replicator pipelines, domain randomization, and dataset export.","source":"@site/docs/module-3-ai-robot-brain/synthetic-data-humanoids.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/synthetic-data-humanoids","permalink":"/docs/module-3-ai-robot-brain/synthetic-data-humanoids","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3-ai-robot-brain/synthetic-data-humanoids.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"synthetic-data-humanoids","title":"Synthetic Data Generation for Humanoid Robots","description":"Isaac Replicator pipelines, domain randomization, and dataset export.","sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Isaac Sim and Photorealistic Simulation","permalink":"/docs/module-3-ai-robot-brain/isaac-sim-photoreal"},"next":{"title":"Isaac ROS VSLAM & Nav2","permalink":"/docs/module-3-ai-robot-brain/nav2-vslam"}},{"id":"module-4-vla/vla-intro","title":"Module 4: Vision-Language-Action (VLA)","description":"Understanding VLA models and multimodal AI for robotics.","source":"@site/docs/module-4-vla/vla-intro.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/vla-intro","permalink":"/docs/module-4-vla/vla-intro","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4-vla/vla-intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"id":"vla-intro","title":"Module 4: Vision-Language-Action (VLA)","description":"Understanding VLA models and multimodal AI for robotics."},"sidebar":"tutorialSidebar","previous":{"title":"Isaac ROS VSLAM & Nav2","permalink":"/docs/module-3-ai-robot-brain/nav2-vslam"},"next":{"title":"Voice-to-Action & Cognitive Planning","permalink":"/docs/module-4-vla/voice-cognitive-planning"}},{"id":"module-4-vla/voice-cognitive-planning","title":"Voice-to-Action & Cognitive Planning","description":"Using OpenAI Whisper and LLMs to translate natural language into robot actions.","source":"@site/docs/module-4-vla/voice-cognitive-planning.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/voice-cognitive-planning","permalink":"/docs/module-4-vla/voice-cognitive-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4-vla/voice-cognitive-planning.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"id":"voice-cognitive-planning","title":"Voice-to-Action & Cognitive Planning","description":"Using OpenAI Whisper and LLMs to translate natural language into robot actions."},"sidebar":"tutorialSidebar","previous":{"title":"Module 4: Vision-Language-Action (VLA)","permalink":"/docs/module-4-vla/vla-intro"},"next":{"title":"Capstone Project: Pick-and-Place with Humanoid","permalink":"/docs/capstone-project/capstone-intro"}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"doc","id":"intro"},{"type":"category","label":"Module 1: ROS 2","items":[{"type":"doc","id":"module-1-ros2/ros2-intro"},{"type":"doc","id":"module-1-ros2/ros2-architecture"},{"type":"doc","id":"module-1-ros2/ros2-communication"},{"type":"doc","id":"module-1-ros2/rclpy-python-agents"},{"type":"doc","id":"module-1-ros2/urdf-humanoids"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: Digital Twin","items":[{"type":"doc","id":"module-2-digital-twin/digital-twin-intro"},{"type":"doc","id":"module-2-digital-twin/physics-fundamentals"},{"type":"doc","id":"module-2-digital-twin/gazebo-setup"},{"type":"doc","id":"module-2-digital-twin/urdf-sdf-humanoids"},{"type":"doc","id":"module-2-digital-twin/sensor-simulation"},{"type":"doc","id":"module-2-digital-twin/unity-hri"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: AI-Robot Brain","items":[{"type":"doc","id":"module-3-ai-robot-brain/isaac-intro"},{"type":"doc","id":"module-3-ai-robot-brain/isaac-ecosystem"},{"type":"doc","id":"module-3-ai-robot-brain/isaac-sim-photoreal"},{"type":"doc","id":"module-3-ai-robot-brain/synthetic-data-humanoids"},{"type":"doc","id":"module-3-ai-robot-brain/nav2-vslam"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: VLA","items":[{"type":"doc","id":"module-4-vla/vla-intro"},{"type":"doc","id":"module-4-vla/voice-cognitive-planning"}],"collapsed":true,"collapsible":true},{"type":"category","label":"Capstone Project","items":[{"type":"doc","id":"capstone-project/capstone-intro"}],"collapsed":true,"collapsible":true}]}}]}},"docusaurus-plugin-content-pages":{"default":[{"type":"jsx","permalink":"/","source":"@site/src/pages/index.js"}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}