"use strict";(globalThis.webpackChunkphysical_ai_robotics_textbook=globalThis.webpackChunkphysical_ai_robotics_textbook||[]).push([[138],{4555(e,n,a){a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>t,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-3-ai-robot-brain/nav2-vslam","title":"Isaac ROS VSLAM & Nav2","description":"Hardware-accelerated Visual SLAM and navigation for bipedal humanoids.","source":"@site/docs/module-3-ai-robot-brain/nav2-vslam.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/nav2-vslam","permalink":"/docs/module-3-ai-robot-brain/nav2-vslam","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3-ai-robot-brain/nav2-vslam.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"id":"nav2-vslam","title":"Isaac ROS VSLAM & Nav2","description":"Hardware-accelerated Visual SLAM and navigation for bipedal humanoids."},"sidebar":"tutorialSidebar","previous":{"title":"Synthetic Data Generation for Humanoid Robots","permalink":"/docs/module-3-ai-robot-brain/synthetic-data-humanoids"},"next":{"title":"Module 4: Vision-Language-Action (VLA)","permalink":"/docs/module-4-vla/vla-intro"}}');var s=a(4848),r=a(8453);const o={sidebar_position:3,id:"nav2-vslam",title:"Isaac ROS VSLAM & Nav2",description:"Hardware-accelerated Visual SLAM and navigation for bipedal humanoids."},t="Isaac ROS VSLAM & Nav2",l={},c=[{value:"1. Learning Objectives",id:"1-learning-objectives",level:2},{value:"2. Core Explanation (Intermediate)",id:"2-core-explanation-intermediate",level:2},{value:"Visual SLAM (VSLAM)",id:"visual-slam-vslam",level:3},{value:"Nav2 for Humanoids",id:"nav2-for-humanoids",level:3},{value:"3. Beginner Simplification",id:"3-beginner-simplification",level:2},{value:"4. Advanced Deep-Dive",id:"4-advanced-deep-dive",level:2},{value:"Hardware Acceleration",id:"hardware-acceleration",level:3},{value:"Nav2 Architecture",id:"nav2-architecture",level:3},{value:"5. Code Examples",id:"5-code-examples",level:2},{value:"Launching Isaac ROS VSLAM",id:"launching-isaac-ros-vslam",level:3},{value:"6. Real-World Context",id:"6-real-world-context",level:2},{value:"7. Exercises",id:"7-exercises",level:2},{value:"8. Assessment Questions",id:"8-assessment-questions",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"isaac-ros-vslam--nav2",children:"Isaac ROS VSLAM & Nav2"})}),"\n",(0,s.jsx)(n.h2,{id:"1-learning-objectives",children:"1. Learning Objectives"}),"\n",(0,s.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Explain"})," the concept of Visual SLAM (Simultaneous Localization and Mapping)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Configure"})," Isaac ROS VSLAM for hardware-accelerated localization."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Understand"})," how Nav2 (Navigation 2) plans paths for robots."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Adapt"})," Nav2 parameters for bipedal humanoid movement constraints."]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"2-core-explanation-intermediate",children:"2. Core Explanation (Intermediate)"}),"\n",(0,s.jsx)(n.h3,{id:"visual-slam-vslam",children:"Visual SLAM (VSLAM)"}),"\n",(0,s.jsxs)(n.p,{children:['For a robot to move, it must answer two questions: "Where am I?" (Localization) and "What does the world look like?" (Mapping).\n',(0,s.jsx)(n.strong,{children:"Visual SLAM"})," uses cameras to track feature points (corners, edges) in the environment to estimate the robot's position and build a map simultaneously."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Isaac ROS VSLAM"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Uses ",(0,s.jsx)(n.strong,{children:"GPU acceleration"})," (Elbrus library) to perform tracking at high frame rates (30+ FPS) on Jetson hardware."]}),"\n",(0,s.jsx)(n.li,{children:"More robust than standard CPU-based SLAM (like ORB-SLAM) in dynamic environments."}),"\n",(0,s.jsxs)(n.li,{children:["Outputs the robot's pose (",(0,s.jsx)(n.code,{children:"/tf"}),") relative to the map frame."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"nav2-for-humanoids",children:"Nav2 for Humanoids"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Nav2"})," is the standard navigation stack for ROS 2. It takes the robot's position (from VSLAM) and a goal pose, then generates velocity commands (",(0,s.jsx)(n.code,{children:"cmd_vel"}),")."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Challenges with Humanoids"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"unlike wheeled robots, humanoids sway when walking."}),"\n",(0,s.jsx)(n.li,{children:"They cannot turn in place instantly (unless using specific gait)."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Footprint"}),": The robot's collision shape changes as it moves legs."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["We use ",(0,s.jsx)(n.strong,{children:"Nav2 Controller Plugins"})," (like MPPI or Regulated Pure Pursuit) tuned for the specific kinematics of the humanoid to ensure smooth path following."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"3-beginner-simplification",children:"3. Beginner Simplification"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"The Explorer"}),":\nImagine you are dropped in a dark room with a flashlight."]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"VSLAM"}),': You look around and remember "The door is there, the table is there." As you move, you count your steps to know where you are.']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Nav2"}),': You want to go to the fridge. You plan a path: "Walk forward 5 steps, turn left, walk 3 steps."']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Isaac ROS"}),": This is like having a photographic memory and a super-fast brain that processes what you see instantly, so you never get lost."]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"4-advanced-deep-dive",children:"4. Advanced Deep-Dive"}),"\n",(0,s.jsx)(n.h3,{id:"hardware-acceleration",children:"Hardware Acceleration"}),"\n",(0,s.jsxs)(n.p,{children:["Isaac ROS VSLAM runs on the ",(0,s.jsx)(n.strong,{children:"NVIDIA PVA (Programmable Vision Accelerator)"})," and ",(0,s.jsx)(n.strong,{children:"GPU"})," on Jetson Orin modules. This offloads the CPU, leaving it free for the high-frequency control loops required for humanoid balance."]}),"\n",(0,s.jsx)(n.h3,{id:"nav2-architecture",children:"Nav2 Architecture"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Global Planner"}),": Calculates the path from A to B (e.g., Dijkstra or A*)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Local Planner (Controller)"}),": Follows the path while avoiding dynamic obstacles (people, pets)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Costmaps"}),": 2D or 3D grids representing safe and unsafe areas. For humanoids, we often use ",(0,s.jsx)(n.strong,{children:"Voxel Layers"})," to detect overhanging obstacles (like tables) that the head might hit."]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"5-code-examples",children:"5. Code Examples"}),"\n",(0,s.jsx)(n.h3,{id:"launching-isaac-ros-vslam",children:"Launching Isaac ROS VSLAM"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# launch_vslam.py\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package='isaac_ros_visual_slam',\n            executable='isaac_ros_visual_slam',\n            name='visual_slam_node',\n            parameters=[{\n                'enable_image_denoising': True,\n                'rectified_images': True,\n                'enable_imu_fusion': True\n            }],\n            remappings=[\n                ('stereo_camera/left/image_rect', '/camera/left/image_rect'),\n                ('stereo_camera/right/image_rect', '/camera/right/image_rect'),\n                ('stereo_camera/left/camera_info', '/camera/left/camera_info'),\n                ('stereo_camera/right/camera_info', '/camera/right/camera_info')\n            ]\n        )\n    ])\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"6-real-world-context",children:"6. Real-World Context"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Warehouse Logistics"}),":\nRobots like ",(0,s.jsx)(n.strong,{children:"Agility Robotics' Digit"})," use VSLAM to navigate warehouses where GPS doesn't work. They use Nav2 to plan paths around boxes and forklifts."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"7-exercises",children:"7. Exercises"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simulation"}),": Launch Isaac Sim with a simple warehouse environment."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"VSLAM"}),": Run the Isaac ROS VSLAM node and visualize the generated map in RViz."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Navigation"}),': Send a "2D Nav Goal" in RViz and watch the robot plan a path to that location.']}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"8-assessment-questions",children:"8. Assessment Questions"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Explain"}),": Why is VSLAM preferred over GPS for indoor humanoid robots?"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Debug"}),": If the robot thinks it is moving backwards when it is moving forwards, what sensor data might be inverted? (IMU or Wheel Odometry)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Design"}),": How would you configure Nav2 for a robot that is very tall but thin? (Adjust the footprint and costmap height)."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453(e,n,a){a.d(n,{R:()=>o,x:()=>t});var i=a(6540);const s={},r=i.createContext(s);function o(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);