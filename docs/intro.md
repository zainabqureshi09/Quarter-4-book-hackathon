---
sidebar_position: 1
---

# Physical AI & Humanoid Robotics

Build robots that see, speak, plan, and act. This textbook takes you from ROS 2 fundamentals to AI-native humanoid control with NVIDIA Isaac and Vision-Language-Action (VLA) agents.

## What You’ll Learn
- **Module 1: ROS 2** — Nodes, Topics, Services, Actions; real-time constraints; Python agents.
- **Module 2: Digital Twin** — Physics simulation, sensors, Gazebo & Unity HRI, URDF/SDF for humanoids.
- **Module 3: AI Brain** — Isaac ROS VSLAM, Nav2 path planning, synthetic data for perception.
- **Module 4: VLA** — Voice-to-Action with Whisper + LLM planning; JSON-enforced action graphs.
- **Capstone** — End-to-end autonomous pipeline: perception → cognition → action.

## How to Use This Textbook
- Each chapter includes: beginner simplification, core explanation, deep-dive, code, exercises, and real-world context.
- Start with Module 1 and follow the **Roadmap** on the homepage.
- Use the sidebar to navigate and the search to find specific topics.

## Quickstart
1. Install Node.js (matching the project `engines.node`).
2. Install dependencies: `npm install`
3. Run locally: `npm run start`
4. Build static site: `npm run build`

## Prerequisites
- Basic Python
- Linux shell familiarity
- Optional: NVIDIA GPU for Isaac ROS acceleration

## Outcomes
- Deploy ROS 2 systems for humanoids
- Simulate complex tasks in photorealistic environments
- Integrate AI models for voice, vision, and planning
